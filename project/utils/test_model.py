#!/usr/bin/env python
# -*- coding:utf-8 -*-
import time

from project.api_info import *
from project.utils.json_operation import *
# from zhipuai import ZhipuAI
from openai import OpenAI
from groq import Groq
# æµ·é¾Ÿæ±¤prompt
# from project.llm_interaction.turtle_prompt import prompt_judge
from project.utils.test_time import timing

# èŠå¤©prompt
from llm_interaction.prompt_design_dog import prompt_judge
from project.utils.print_format import colored_output

# client = OpenAI(api_key=OPENAI_API_KEY)
# client = ZhipuAI(api_key=ZHIPU_API_KEY)
client = Groq(api_key=GROQ_API_KEY)


def construct_prompts(user_input):
    prompts = [
        # ç³»ç»Ÿæç¤º
        role_content_json("system", "ç”¨ä¸­æ–‡å›ç­”"),
        # ç”¨æˆ·è¾“å…¥
        role_content_json("user", user_input)
    ]
    return prompts


@timing
def llm_interaction(user_input):
    """
    Send the message to the model with a list of tools and prompt the model to use the tools.
    Tools is a list of dict describing functions.
    Return the chosen function.
    """
    # æ„é€ prompts
    prompts = construct_prompts(user_input)

    # æ¨¡å‹äº¤äº’
    reply = client.chat.completions.create(
        # model="glm-4", messages=prompts,
        # model='gpt-3.5-turbo', messages=prompts,
        model="llama3-8b-8192", messages=prompts,
    )
    # é€‰æ‹©äº†è¿”å›å·¥å…·
    model_reply = reply.choices[0].message.content
    # choice = completion.choices[0].message.tool_calls[0].function
    colored_output("ğŸ¤– Groq:\n" + model_reply, "yellow")

    return model_reply


# æµ‹è¯•ï¼šåœ¨æ­¤å¤„ä¸æ¨¡å‹å¯¹è¯
if __name__ == "__main__":
    try:
        while True:
            colored_output("â“ è¯·è¾“å…¥ï¼š", "green")
            user_input = input()
            llm_interaction(user_input)
    # æ£€æŸ¥æ˜¯å¦é€€å‡º
    except KeyboardInterrupt:
        colored_output("ğŸ‘‹ å†è§ï¼æœŸå¾…ä¸‹æ¬¡ä¸æ‚¨çš„äº¤è°ˆã€‚", "yellow")


