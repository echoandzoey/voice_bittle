from groq import Groq

from api_info import *
from utils.json_operation import *
# èŠå¤©prompt
from utils.print_format import colored_output
# æµ·é¾Ÿæ±¤prompt
# from project.llm_interaction.turtle_prompt import prompt_judge
from utils.test_time import timing

# client = OpenAI(api_key=OPENAI_API_KEY)
# client = ZhipuAI(api_key=ZHIPU_API_KEY)
client = Groq(api_key=GROQ_API_KEY)


@timing
def get_llm_msg(prompts):
    """
    Send the message to the model with a list of tools and prompt the model to use the tools.
    Tools is a list of dict describing functions.
    Return the chosen function.
    """

    # æ¨¡å‹äº¤äº’
    reply = client.chat.completions.create(
        # model="glm-4", messages=prompts,
        # model='gpt-3.5-turbo', messages=prompts,
        model="llama3-8b-8192", messages=prompts,
    )
    # æå–å›å¤å†…å®¹
    reply_content = reply.choices[0].message.content

    # æ‰“å°
    colored_output("ğŸ¦´ å›å¤å†…å®¹ï¼š" + reply_content, "yellow")

    # æ ¼å¼åŒ–å›å¤å†…å®¹ï¼šæ£€æŸ¥jsonæ ¼å¼ï¼Œå¹¶å°†jsonå­—ç¬¦ä¸²å˜ä¸ºå­—å…¸
    reply_json = format_json(reply_content)


    return reply_json
